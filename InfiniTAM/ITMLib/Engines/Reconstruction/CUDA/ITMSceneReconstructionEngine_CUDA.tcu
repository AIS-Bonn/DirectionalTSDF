// Copyright 2014-2017 Oxford University Innovation Limited and the authors of InfiniTAM

#pragma once

#include <memory>
#include <ITMLib/Utils/ITMLibSettings.h>
#include <ITMLib/Utils/ITMSceneParams.h>
#include <ITMLib/Utils/ITMTimer.h>
#include "ITMSceneReconstructionEngine_CUDA.h"

#include "../Shared/ITMSceneReconstructionEngine_Shared.h"
#include "../../../Objects/RenderStates/ITMRenderState_VH.h"
#include "../../../Utils/ITMCUDAUtils.h"

using namespace ITMLib;

namespace
{
// device functions

void
__global__
rayCastClearSum_device(
	const ITMVoxelBlockHash::IndexData *hashTable,
	const int *visibleEntryIds,
	VoxelRayCastingSum *entriesRayCasting
)
{
	int x = threadIdx.x, y = threadIdx.y, z = threadIdx.z;
	int locId = x + y * SDF_BLOCK_SIZE + z * SDF_BLOCK_SIZE * SDF_BLOCK_SIZE;
	int entryId = blockIdx.x;

	const ITMHashEntry &hashEntry = hashTable[visibleEntryIds[entryId]];
	if (not hashEntry.IsValid())
		return;

	entriesRayCasting[hashEntry.ptr * SDF_BLOCK_SIZE3 + locId].reset();
}

__global__
void rayCastCombine_device(
	ITMVoxel *localVBA,
	const ITMVoxelBlockHash::IndexData *hashTable,
	const int *visibleEntryIds,
	const VoxelRayCastingSum *entriesRayCasting,
	const ITMSceneParams sceneParams
)
{
	int x = threadIdx.x, y = threadIdx.y, z = threadIdx.z;
	int locId = VoxelIndicesToOffset(x, y, z);
	int entryId = blockIdx.x;

	const ITMHashEntry &hashEntry = hashTable[visibleEntryIds[entryId]];
	if (not hashEntry.IsValid())
		return;
	ITMVoxel *localVoxelBlock = &(localVBA[hashEntry.ptr * SDF_BLOCK_SIZE3]);
	const VoxelRayCastingSum *rayCastingSum = &(entriesRayCasting[hashEntry.ptr * SDF_BLOCK_SIZE3]);
	rayCastCombine(localVoxelBlock[locId], rayCastingSum[locId], sceneParams);
}

__global__
void rayCastUpdate_device(
	Vector2i imgSize, float* depth, Vector4f* depthNormals,
	const Matrix4f invM_d,
	const Vector4f invProjParams_d, const Vector4f invProjParams_rgb,
	const ITMFusionParams fusionParams,
	const ITMSceneParams sceneParams,
	const ITMHashEntry* hashTable,
	VoxelRayCastingSum* entriesRayCasting,
	ITMVoxel *localVBA)
{
	int x = threadIdx.x + blockIdx.x * blockDim.x;
	int y = threadIdx.y + blockIdx.y * blockDim.y;

	if (x >= imgSize.x or y >= imgSize.y)
		return;

	rayCastUpdate(x, y, imgSize, depth, depthNormals, invM_d,
	              invProjParams_d, invProjParams_rgb, fusionParams, sceneParams,
	              hashTable, entriesRayCasting);
}

__global__
void rayCastCarveSpace_device(
	Vector2i imgSize, float* depth, Vector4f* depthNormals,
	const Matrix4f invM_d,
	const Vector4f invProjParams_d, const Vector4f invProjParams_rgb,
	const ITMFusionParams fusionParams,
	const ITMSceneParams sceneParams,
	const ITMHashEntry* hashTable,
	VoxelRayCastingSum* entriesRayCasting,
	ITMVoxel *localVBA)
{
	int x = threadIdx.x + blockIdx.x * blockDim.x;
	int y = threadIdx.y + blockIdx.y * blockDim.y;

	if (x >= imgSize.x or y >= imgSize.y)
		return;

	rayCastCarveSpace(x, y, imgSize, depth, depthNormals, invM_d,
	                  invProjParams_d, invProjParams_rgb, fusionParams, sceneParams,
	                  hashTable, entriesRayCasting, localVBA);
}

template<bool stopMaxW>
__global__ void voxelProjectionCarveSpace_device(
	ITMVoxel *localVBA, VoxelRayCastingSum* entriesRayCasting, const ITMHashEntry *hashTable, int *visibleEntryIDs,
	const Vector4u *rgb, Vector2i rgbImgSize, const float *depth, const Vector4f *depthNormals,
	const float *confidence, Vector2i depthImgSize, Matrix4f M_d, Matrix4f M_rgb, Vector4f projParams_d,
	Vector4f projParams_rgb, const ITMFusionParams fusionParams,
	const ITMSceneParams sceneParams)
{
	Vector3i globalPos;
	int entryId = visibleEntryIDs[blockIdx.x];

	const ITMHashEntry &currentHashEntry = hashTable[entryId];

	if (currentHashEntry.ptr < 0) return;

	globalPos = currentHashEntry.pos.toInt() * SDF_BLOCK_SIZE;

	ITMVoxel *localVoxelBlock = &(localVBA[currentHashEntry.ptr * SDF_BLOCK_SIZE3]);
	VoxelRayCastingSum *localRayCastingSum = &(entriesRayCasting[currentHashEntry.ptr * SDF_BLOCK_SIZE3]);

	int x = threadIdx.x, y = threadIdx.y, z = threadIdx.z;

	Vector4f pt_model; int locId;

	locId = x + y * SDF_BLOCK_SIZE + z * SDF_BLOCK_SIZE * SDF_BLOCK_SIZE;

	if (stopMaxW) if (localVoxelBlock[locId].w_depth == sceneParams.maxW) return;
	//if (approximateIntegration) if (localVoxelBlock[locId].w_depth != 0) return;

	float voxelSize = sceneParams.voxelSize;
	pt_model.x = (float)(globalPos.x + x) * voxelSize;
	pt_model.y = (float)(globalPos.y + y) * voxelSize;
	pt_model.z = (float)(globalPos.z + z) * voxelSize;
	pt_model.w = 1.0f;

	voxelProjectionCarveSpace(
		localVoxelBlock[locId], localRayCastingSum[locId],
		TSDFDirection(currentHashEntry.direction),
		pt_model, M_d, projParams_d, M_rgb, projParams_rgb,
		fusionParams, sceneParams, depth, depthNormals, confidence,
		depthImgSize, rgb, rgbImgSize);
}

template<bool stopMaxW>
__global__ void integrateIntoScene_device(ITMVoxel *localVBA, const ITMHashEntry *hashTable, int *visibleEntryIDs,
	const Vector4u *rgb, Vector2i rgbImgSize, const float *depth, const Vector4f *depthNormals, const float *confidence, Vector2i depthImgSize, Matrix4f M_d, Matrix4f M_rgb, Vector4f projParams_d,
	Vector4f projParams_rgb, float _voxelSize, const ITMFusionParams fusionParams, const ITMSceneParams sceneParams)
{
	Vector3i globalPos;
	int entryId = visibleEntryIDs[blockIdx.x];

	const ITMHashEntry &currentHashEntry = hashTable[entryId];

	if (currentHashEntry.ptr < 0) return;

	globalPos = currentHashEntry.pos.toInt() * SDF_BLOCK_SIZE;

	ITMVoxel *localVoxelBlock = &(localVBA[currentHashEntry.ptr * SDF_BLOCK_SIZE3]);

	int x = threadIdx.x, y = threadIdx.y, z = threadIdx.z;

	Vector4f pt_model; int locId;

	locId = x + y * SDF_BLOCK_SIZE + z * SDF_BLOCK_SIZE * SDF_BLOCK_SIZE;

	if (stopMaxW) if (localVoxelBlock[locId].w_depth == sceneParams.maxW) return;
	//if (approximateIntegration) if (localVoxelBlock[locId].w_depth != 0) return;

	pt_model.x = (float)(globalPos.x + x) * _voxelSize;
	pt_model.y = (float)(globalPos.y + y) * _voxelSize;
	pt_model.z = (float)(globalPos.z + z) * _voxelSize;
	pt_model.w = 1.0f;

	std::conditional<ITMVoxel::hasColorInformation, ComputeUpdatedVoxelInfo<true, ITMVoxel>, ComputeUpdatedVoxelInfo<false, ITMVoxel>>::type::compute(
			localVoxelBlock[locId], TSDFDirection(currentHashEntry.direction),
		pt_model, M_d, projParams_d, M_rgb, projParams_rgb, fusionParams, sceneParams, depth, depthNormals, confidence,
		depthImgSize, rgb, rgbImgSize);
}

__global__ void buildHashAllocAndVisibleType_device(HashEntryAllocType *entriesAllocType, HashEntryVisibilityType *entriesVisibleType,
	                                                  Vector4s *blockCoords, TSDFDirection *blockDirections, const float *depth,
	                                                  const Vector4f *depthNormal, Matrix4f invM_d, Vector4f projParams_d, float mu, Vector2i _imgSize,
	                                                  float _voxelSize, ITMHashEntry *hashTable, float viewFrustum_min, float viewFrustum_max,
	                                                  const ITMFusionParams fusionParams)
{
	int x = threadIdx.x + blockIdx.x * blockDim.x, y = threadIdx.y + blockIdx.y * blockDim.y;

	if (x > _imgSize.x - 1 || y > _imgSize.y - 1) return;

	if (fusionParams.useSpaceCarving)
		buildSpaceCarvingVisibleType(entriesVisibleType, x, y, blockCoords, blockDirections,
		                             depth, depthNormal, invM_d, projParams_d, mu, _imgSize, _voxelSize, hashTable,
		                             viewFrustum_min, viewFrustum_max, fusionParams);

	buildHashAllocAndVisibleType(entriesAllocType, entriesVisibleType, x, y, blockCoords, blockDirections,
		depth, depthNormal, invM_d, projParams_d, mu, _imgSize, _voxelSize, hashTable, viewFrustum_min,
		viewFrustum_max, fusionParams);
}

__global__ void setToType3(HashEntryVisibilityType *entriesVisibleType, int *visibleEntryIDs, int noVisibleEntries)
{
	int entryId = threadIdx.x + blockIdx.x * blockDim.x;
	if (entryId > noVisibleEntries - 1) return;
	entriesVisibleType[visibleEntryIDs[entryId]] = PREVIOUSLY_VISIBLE;
}

__global__ void allocateVoxelBlocksList_device(int *voxelAllocationList, int *excessAllocationList, ITMHashEntry *hashTable, int noTotalEntries,
	AllocationTempData *allocData, HashEntryAllocType *entriesAllocType, HashEntryVisibilityType *entriesVisibleType,
	Vector4s *blockCoords, TSDFDirection *blockDirections)
{
	int targetIdx = threadIdx.x + blockIdx.x * blockDim.x;
	if (targetIdx > noTotalEntries - 1) return;

	int vbaIdx, exlIdx;

	switch (entriesAllocType[targetIdx])
	{
	case ALLOCATE_ORDERED: //needs allocation, fits in the ordered list
		vbaIdx = atomicSub(&allocData->noAllocatedVoxelEntries, 1);

		if (vbaIdx >= 0) //there is room in the voxel block array
		{
			Vector4s pt_block_all = blockCoords[targetIdx];

			ITMHashEntry hashEntry;
			hashEntry.pos.x = pt_block_all.x; hashEntry.pos.y = pt_block_all.y; hashEntry.pos.z = pt_block_all.z;
			hashEntry.ptr = voxelAllocationList[vbaIdx];
			hashEntry.offset = 0;
			hashEntry.direction = static_cast<TSDFDirection_type>(blockDirections[targetIdx]);

			hashTable[targetIdx] = hashEntry;

			atomicAdd(&allocData->noAllocationsPerDirection[hashEntry.direction % 255], 1);
		}
		else
		{
			// Mark entry as not visible since we couldn't allocate it but buildHashAllocAndVisibleType changed its state.
			entriesVisibleType[targetIdx] = INVISIBLE;

			// Restore the previous value to avoid leaks.
			atomicAdd(&allocData->noAllocatedVoxelEntries, 1);
		}
		break;

	case ALLOCATE_EXCESS: //needs allocation in the excess list
		vbaIdx = atomicSub(&allocData->noAllocatedVoxelEntries, 1);
		exlIdx = atomicSub(&allocData->noAllocatedExcessEntries, 1);

		if (vbaIdx >= 0 && exlIdx >= 0) //there is room in the voxel block array and excess list
		{
			Vector4s pt_block_all = blockCoords[targetIdx];

			ITMHashEntry hashEntry;
			hashEntry.pos.x = pt_block_all.x; hashEntry.pos.y = pt_block_all.y; hashEntry.pos.z = pt_block_all.z;
			hashEntry.ptr = voxelAllocationList[vbaIdx];
			hashEntry.offset = 0;
			hashEntry.direction = static_cast<TSDFDirection_type>(blockDirections[targetIdx]);

			int exlOffset = excessAllocationList[exlIdx];

			hashTable[targetIdx].offset = exlOffset + 1; //connect to child

			hashTable[SDF_BUCKET_NUM + exlOffset] = hashEntry; //add child to the excess list

			entriesVisibleType[SDF_BUCKET_NUM + exlOffset] = VISIBLE_IN_MEMORY; //make child visible

			atomicAdd(&allocData->noAllocationsPerDirection[hashEntry.direction % 255], 1);
		}
		else
		{
			// No need to mark the entry as not visible since buildHashAllocAndVisibleType did not mark it.
			// Restore the previous values to avoid leaks.
			atomicAdd(&allocData->noAllocatedVoxelEntries, 1);
			atomicAdd(&allocData->noAllocatedExcessEntries, 1);
		}

		break;
	}
}

__global__ void reAllocateSwappedOutVoxelBlocks_device(int *voxelAllocationList, ITMHashEntry *hashTable, int noTotalEntries,
	AllocationTempData *allocData, /*int *noAllocatedVoxelEntries,*/ HashEntryVisibilityType *entriesVisibleType)
{
	int targetIdx = threadIdx.x + blockIdx.x * blockDim.x;
	if (targetIdx > noTotalEntries - 1) return;

	int vbaIdx;
	int hashEntry_ptr = hashTable[targetIdx].ptr;

	if (entriesVisibleType[targetIdx] > 0 && hashEntry_ptr == -1) //it is visible and has been previously allocated inside the hash, but deallocated from VBA
	{
		vbaIdx = atomicSub(&allocData->noAllocatedVoxelEntries, 1);
		if (vbaIdx >= 0) hashTable[targetIdx].ptr = voxelAllocationList[vbaIdx];
		else atomicAdd(&allocData->noAllocatedVoxelEntries, 1);
	}
}

template<bool useSwapping>
__global__ void buildVisibleList_kernel(ITMHashEntry* hashTable, ITMHashSwapState* swapStates, int noTotalEntries,
                                        int* visibleEntryIDs, AllocationTempData* allocData,
                                        HashEntryVisibilityType* entriesVisibleType,
                                        Matrix4f M_d, Vector4f projParams_d, Vector2i depthImgSize, float voxelSize)
{
	int targetIdx = threadIdx.x + blockIdx.x * blockDim.x;
	if (targetIdx > noTotalEntries - 1) return;

	__shared__ bool shouldPrefix;
	shouldPrefix = false;
	__syncthreads();

	buildVisibleList<useSwapping>(hashTable, swapStates, noTotalEntries, visibleEntryIDs,
	                              allocData, entriesVisibleType, M_d, projParams_d, depthImgSize, voxelSize,
	                              targetIdx);

	HashEntryVisibilityType hashVisibleType = entriesVisibleType[targetIdx];
	if (hashVisibleType > 0) shouldPrefix = true;

	__syncthreads();

	if (shouldPrefix)
	{
		int offset = computePrefixSum_device<int>(hashVisibleType > 0, &allocData->noVisibleEntries, blockDim.x * blockDim.y, threadIdx.x);
		if (offset != -1) visibleEntryIDs[offset] = targetIdx;
	}

#if 0
	// "active list": blocks that have new information from depth image
	// currently not used...
	__syncthreads();

	if (shouldPrefix)
	{
		int offset = computePrefixSum_device<int>(hashVisibleType == 1, noActiveEntries, blockDim.x * blockDim.y, threadIdx.x);
		if (offset != -1) activeEntryIDs[offset] = targetIdx;
	}
#endif
}

}

ITMSceneReconstructionEngine_CUDA::ITMSceneReconstructionEngine_CUDA(
	const std::shared_ptr<const ITMLibSettings>& settings)
	: ITMSceneReconstructionEngine(settings)
{
	ORcudaSafeCall(cudaMalloc((void**) &allocationTempData_device, sizeof(AllocationTempData)));
	ORcudaSafeCall(cudaMallocHost((void**) &allocationTempData_host, sizeof(AllocationTempData)));

	int noTotalEntries = ITMVoxelBlockHash::noTotalEntries;
	ORcudaSafeCall(cudaMalloc((void**) &entriesAllocType_device, noTotalEntries * sizeof(HashEntryAllocType)));
	ORcudaSafeCall(cudaMalloc((void**) &blockCoords_device, noTotalEntries * sizeof(Vector4s)));
	ORcudaSafeCall(cudaMalloc((void**) &blockDirections_device, noTotalEntries * sizeof(TSDFDirection)));
	if (settings->fusionParams.fusionMode != FusionMode::FUSIONMODE_VOXEL_PROJECTION)
	{
		this->entriesRayCasting = new ORUtils::MemoryBlock<VoxelRayCastingSum>(
			ITMVoxelBlockHash::noLocalEntries * SDF_BLOCK_SIZE3, MEMORYDEVICE_CUDA);
	}
}


void
ITMSceneReconstructionEngine_CUDA::IntegrateIntoSceneRayCasting(
	Scene* scene, const ITMView* view, const ITMTrackingState* trackingState,
	const ITMRenderState* renderState)
{
	ITMTimer timer;
	timer.Tick();

	Matrix4f invM_d = trackingState->pose_d->GetInvM();
	Vector4f projParams_d = view->calib.intrinsics_d.projectionParamsSimple.all;
	Vector4f projParams_rgb = view->calib.intrinsics_rgb.projectionParamsSimple.all;

	float* depth = view->depth->GetData(MEMORYDEVICE_CUDA);
	Vector4f* depthNormals = view->depthNormal->GetData(MEMORYDEVICE_CUDA);
	float* confidence = view->depthConfidence->GetData(MEMORYDEVICE_CUDA);
	Vector4u* rgb = view->rgb->GetData(MEMORYDEVICE_CUDA);
	ITMVoxel* localVBA = scene->localVBA.GetVoxelBlocks();
	ITMHashEntry* hashTable = scene->index.GetEntries();

	Vector2i depthImgSize = view->depth->noDims;

	VoxelRayCastingSum* entriesRayCasting = nullptr;
	entriesRayCasting = this->entriesRayCasting->GetData(MEMORYDEVICE_CUDA);

	Vector4f invProjParams_d = invertProjectionParams(projParams_d);

	/// 1. Clear ray casting sum fields
	auto* renderState_vh = (ITMRenderState_VH*) renderState;
	dim3 blockSizeCombine(SDF_BLOCK_SIZE, SDF_BLOCK_SIZE, SDF_BLOCK_SIZE);
	dim3 gridSizeCombine(renderState_vh->noVisibleEntries);
	rayCastClearSum_device << < gridSizeCombine, blockSizeCombine >> > (
		hashTable,
			renderState_vh->GetVisibleEntryIDs(),
			entriesRayCasting
	);
	ORcudaKernelCheck;

	/// 2. Ray cast update for every pixel
	dim3 blockSizeUpdate(16, 16);
	dim3 gridSizeUpdate((int) ceil((float) depthImgSize.x / (float) blockSizeUpdate.x),
	                    (int) ceil((float) depthImgSize.y / (float) blockSizeUpdate.y));
	rayCastUpdate_device << < gridSizeUpdate, blockSizeUpdate >> > (
		depthImgSize, depth, depthNormals, invM_d, invProjParams_d, projParams_rgb, this->settings->fusionParams, this->settings->sceneParams,
			hashTable, entriesRayCasting, localVBA);
	ORcudaKernelCheck;
	this->timeStats.fusion += timer.Tock();

	/// 3. Ray cast space carving for every pixel
	timer.Tick();
	if (this->settings->fusionParams.useSpaceCarving)
	{
		if (this->settings->fusionParams.carvingMode == CarvingMode::CARVINGMODE_RAY_CASTING)
		{
			rayCastCarveSpace_device << < gridSizeUpdate, blockSizeUpdate >> > (
				depthImgSize, depth, depthNormals, invM_d, invProjParams_d, projParams_rgb, this->settings->fusionParams, this->settings->sceneParams,
					hashTable, entriesRayCasting, localVBA);
			ORcudaKernelCheck;
		} else
		{
			Vector2i rgbImgSize = view->rgb->noDims;
			int* visibleEntryIDs = renderState_vh->GetVisibleEntryIDs();
			Matrix4f M_d = trackingState->pose_d->GetM();
			Matrix4f M_rgb = view->calib.trafo_rgb_to_depth.calib_inv * M_d;

			dim3 blockSizeVoxelProjection(SDF_BLOCK_SIZE, SDF_BLOCK_SIZE, SDF_BLOCK_SIZE);
			dim3 gridSizeVoxelProjection(renderState_vh->noVisibleEntries);
			voxelProjectionCarveSpace_device<false> << < gridSizeVoxelProjection, blockSizeVoxelProjection >> > (
				localVBA, entriesRayCasting, hashTable, visibleEntryIDs,
					rgb, rgbImgSize, depth, depthNormals,
					confidence, depthImgSize, M_d, M_rgb, projParams_d,
					projParams_rgb, this->settings->fusionParams,
					this->settings->sceneParams);
			ORcudaKernelCheck;
		}
	}
	this->timeStats.carving = timer.Tock();

	/// 4. Collect per voxel summation values, update voxel
	timer.Tick();
	rayCastCombine_device << < gridSizeCombine, blockSizeCombine >> > (
		localVBA,
			hashTable,
			renderState_vh->GetVisibleEntryIDs(),
			entriesRayCasting,
			this->settings->sceneParams
	);
	ORcudaKernelCheck;

	this->timeStats.fusion += timer.Tock();
}

ITMSceneReconstructionEngine_CUDA::~ITMSceneReconstructionEngine_CUDA(void)
{
	ORcudaSafeCall(cudaFreeHost(allocationTempData_host));
	ORcudaSafeCall(cudaFree(allocationTempData_device));
	ORcudaSafeCall(cudaFree(entriesAllocType_device));
	ORcudaSafeCall(cudaFree(blockCoords_device));
	ORcudaSafeCall(cudaFree(blockDirections_device));
	if (this->settings->fusionParams.fusionMode != FusionMode::FUSIONMODE_VOXEL_PROJECTION)
	{
		delete this->entriesRayCasting;
	}
}

void ITMSceneReconstructionEngine_CUDA::ResetScene(Scene* scene)
{
	int numBlocks = scene->index.getNumAllocatedVoxelBlocks();
	int blockSize = scene->index.getVoxelBlockSize();

	ITMVoxel* voxelBlocks_ptr = scene->localVBA.GetVoxelBlocks();
	memsetKernel<ITMVoxel>(voxelBlocks_ptr, ITMVoxel(), numBlocks * blockSize);
	int* vbaAllocationList_ptr = scene->localVBA.GetAllocationList();
	fillArrayKernel<int>(vbaAllocationList_ptr, numBlocks);
	scene->localVBA.lastFreeBlockId = numBlocks - 1;

	ITMHashEntry tmpEntry;
	memset(&tmpEntry, 0, sizeof(ITMHashEntry));
	tmpEntry.ptr = -2;
	ITMHashEntry* hashEntry_ptr = scene->index.GetEntries();
	memsetKernel<ITMHashEntry>(hashEntry_ptr, tmpEntry, scene->index.noTotalEntries);
	int* excessList_ptr = scene->index.GetExcessAllocationList();
	fillArrayKernel<int>(excessList_ptr, SDF_EXCESS_LIST_SIZE);

	scene->index.SetLastFreeExcessListId(SDF_EXCESS_LIST_SIZE - 1);
}

void ITMSceneReconstructionEngine_CUDA::AllocateSceneFromDepth(Scene* scene,
                                                               const ITMView* view,
                                                               const ITMTrackingState* trackingState,
                                                               const ITMRenderState* renderState,
                                                               bool onlyUpdateVisibleList, bool resetVisibleList)
{
	ITMTimer timer;
	timer.Tick();
	Vector2i depthImgSize = view->depth->noDims;
	float voxelSize = scene->sceneParams->voxelSize;

	Matrix4f M_d, invM_d;
	Vector4f projParams_d, invProjParams_d;

	ITMRenderState_VH* renderState_vh = (ITMRenderState_VH*) renderState;

	if (resetVisibleList) renderState_vh->noVisibleEntries = 0;

	M_d = trackingState->pose_d->GetM();
	M_d.inv(invM_d);

	projParams_d = view->calib.intrinsics_d.projectionParamsSimple.all;
	invProjParams_d = invertProjectionParams(projParams_d);

	float mu = scene->sceneParams->mu;

	float* depth = view->depth->GetData(MEMORYDEVICE_CUDA);
	Vector4f* depthNormal = view->depthNormal->GetData(MEMORYDEVICE_CUDA);
	int* voxelAllocationList = scene->localVBA.GetAllocationList();
	int* excessAllocationList = scene->index.GetExcessAllocationList();
	ITMHashEntry* hashTable = scene->index.GetEntries();
	ITMHashSwapState* swapStates = scene->globalCache != NULL ? scene->globalCache->GetSwapStates(true) : 0;

	int noTotalEntries = scene->index.noTotalEntries;

	int* visibleEntryIDs = renderState_vh->GetVisibleEntryIDs();
	HashEntryVisibilityType* entriesVisibleType = renderState_vh->GetEntriesVisibleType();

	dim3 cudaBlockSizeHV(16, 16);
	dim3 gridSizeHV((int) ceil((float) depthImgSize.x / (float) cudaBlockSizeHV.x),
	                (int) ceil((float) depthImgSize.y / (float) cudaBlockSizeHV.y));

	dim3 cudaBlockSizeAL(256, 1);
	dim3 gridSizeAL((int) ceil((float) noTotalEntries / (float) cudaBlockSizeAL.x));

	dim3 cudaBlockSizeVS(256, 1);
	dim3 gridSizeVS((int) ceil((float) renderState_vh->noVisibleEntries / (float) cudaBlockSizeVS.x));

	AllocationTempData* tempData = (AllocationTempData*) allocationTempData_host;
	tempData->noAllocatedVoxelEntries = scene->localVBA.lastFreeBlockId;
	tempData->noAllocatedExcessEntries = scene->index.GetLastFreeExcessListId();
	tempData->noVisibleEntries = 0;
	memcpy(tempData->noAllocationsPerDirection, scene->localVBA.noAllocationsPerDirection,
	       sizeof(unsigned int) * N_DIRECTIONS);
	if (scene->localVBA.lastFreeBlockId <= 0)
	{
		printf("No more free blocks. Allocation stopped.\n");
	}
	ORcudaSafeCall(
		cudaMemcpyAsync(allocationTempData_device, tempData, sizeof(AllocationTempData), cudaMemcpyHostToDevice));

	ORcudaSafeCall(cudaMemsetAsync(entriesAllocType_device, 0, sizeof(unsigned char) * noTotalEntries));

	if (gridSizeVS.x > 0)
	{
		setToType3 << < gridSizeVS, cudaBlockSizeVS >> >
		                            (entriesVisibleType, visibleEntryIDs, renderState_vh->noVisibleEntries);
		ORcudaKernelCheck;
	}

	buildHashAllocAndVisibleType_device << < gridSizeHV, cudaBlockSizeHV >> >
	                                                     (entriesAllocType_device, entriesVisibleType,
		                                                     blockCoords_device, blockDirections_device, depth, depthNormal, invM_d, invProjParams_d, mu, depthImgSize, voxelSize, hashTable,
		                                                     scene->sceneParams->viewFrustum_min, scene->sceneParams->viewFrustum_max, this->settings->fusionParams);
	ORcudaKernelCheck;

	this->timeStats.buildingVisibilityList = timer.Tock();

	bool useSwapping = scene->globalCache != NULL;

	timer.Tick();
	if (onlyUpdateVisibleList) useSwapping = false;
	if (!onlyUpdateVisibleList)
	{
		allocateVoxelBlocksList_device << < gridSizeAL, cudaBlockSizeAL >> >
		                                                (voxelAllocationList, excessAllocationList, hashTable,
			                                                noTotalEntries, (AllocationTempData*) allocationTempData_device, entriesAllocType_device, entriesVisibleType,
			                                                blockCoords_device, blockDirections_device);
		ORcudaKernelCheck;
	}
	this->timeStats.allocation += timer.Tock();

	timer.Tick();
	if (useSwapping)
	{
		buildVisibleList_kernel<true> << < gridSizeAL, cudaBlockSizeAL >> >
		                                               (hashTable, swapStates, noTotalEntries, visibleEntryIDs,
			                                               (AllocationTempData*) allocationTempData_device, entriesVisibleType, M_d, projParams_d, depthImgSize, voxelSize);
		ORcudaKernelCheck;
	} else
	{
		buildVisibleList_kernel<false> << < gridSizeAL, cudaBlockSizeAL >> >
		                                                (hashTable, swapStates, noTotalEntries, visibleEntryIDs,
			                                                (AllocationTempData*) allocationTempData_device, entriesVisibleType, M_d, projParams_d, depthImgSize, voxelSize);
		ORcudaKernelCheck;
	}
	this->timeStats.buildingVisibilityList += timer.Tock();

	//reallocate deleted entries from previous swap operation
	if (useSwapping)
	{
		timer.Tick();
		reAllocateSwappedOutVoxelBlocks_device << < gridSizeAL, cudaBlockSizeAL >> >
		                                                        (voxelAllocationList, hashTable, noTotalEntries,
			                                                        (AllocationTempData*) allocationTempData_device, entriesVisibleType);
		ORcudaKernelCheck;
		this->timeStats.swapping += timer.Tock();
	}

	ORcudaSafeCall(cudaMemcpy(tempData, allocationTempData_device, sizeof(AllocationTempData), cudaMemcpyDeviceToHost));
	renderState_vh->noVisibleEntries = tempData->noVisibleEntries;
	scene->localVBA.lastFreeBlockId = tempData->noAllocatedVoxelEntries;
	scene->index.SetLastFreeExcessListId(tempData->noAllocatedExcessEntries);
	memcpy(scene->localVBA.noAllocationsPerDirection, tempData->noAllocationsPerDirection,
	       sizeof(unsigned int) * N_DIRECTIONS);
}

void ITMSceneReconstructionEngine_CUDA::IntegrateIntoSceneVoxelProjection(
	Scene* scene, const ITMView* view,
	const ITMTrackingState* trackingState, const ITMRenderState* renderState)
{
	ITMTimer timer;
	timer.Tick();

	Vector2i rgbImgSize = view->rgb->noDims;
	Vector2i depthImgSize = view->depth->noDims;
	float voxelSize = scene->sceneParams->voxelSize;

	Matrix4f M_d, M_rgb;
	Vector4f projParams_d, projParams_rgb;

	ITMRenderState_VH* renderState_vh = (ITMRenderState_VH*) renderState;
	if (renderState_vh->noVisibleEntries == 0) return;

	M_d = trackingState->pose_d->GetM();
	if (ITMVoxel::hasColorInformation) M_rgb = view->calib.trafo_rgb_to_depth.calib_inv * M_d;

	projParams_d = view->calib.intrinsics_d.projectionParamsSimple.all;
	projParams_rgb = view->calib.intrinsics_rgb.projectionParamsSimple.all;

	float* depth = view->depth->GetData(MEMORYDEVICE_CUDA);
	Vector4f* depthNormals = nullptr;
	if (this->settings->fusionParams.useWeighting or
	    this->settings->fusionParams.fusionMetric == FUSIONMETRIC_POINT_TO_PLANE)
		depthNormals = view->depthNormal->GetData(MEMORYDEVICE_CUDA);
	float* confidence = view->depthConfidence->GetData(MEMORYDEVICE_CUDA);
	Vector4u* rgb = view->rgb->GetData(MEMORYDEVICE_CUDA);
	ITMVoxel* localVBA = scene->localVBA.GetVoxelBlocks();
	ITMHashEntry* hashTable = scene->index.GetEntries();

	int* visibleEntryIDs = renderState_vh->GetVisibleEntryIDs();

	dim3 cudaBlockSize(SDF_BLOCK_SIZE, SDF_BLOCK_SIZE, SDF_BLOCK_SIZE);
	dim3 gridSize(renderState_vh->noVisibleEntries);

	if (scene->sceneParams->stopIntegratingAtMaxW)
	{
		integrateIntoScene_device<true> << < gridSize, cudaBlockSize >> > (localVBA, hashTable, visibleEntryIDs,
			rgb, rgbImgSize, depth, depthNormals, confidence, depthImgSize, M_d, M_rgb, projParams_d, projParams_rgb, voxelSize,
			this->settings->fusionParams, this->settings->sceneParams);
		ORcudaKernelCheck;
	} else
	{
		integrateIntoScene_device<false> << < gridSize, cudaBlockSize >> > (localVBA, hashTable, visibleEntryIDs,
			rgb, rgbImgSize, depth, depthNormals, confidence, depthImgSize, M_d, M_rgb, projParams_d, projParams_rgb, voxelSize,
			this->settings->fusionParams, this->settings->sceneParams);
		ORcudaKernelCheck;
	}

	this->timeStats.fusion = timer.Tock();
}
